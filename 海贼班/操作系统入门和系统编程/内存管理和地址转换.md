### 内存管理的基本思想

每个进程都拥有自己的 地址空间（Address Space），包括这个进程可以使用的全部地址和其中存储的所有数据；为了防止不同进程修改彼此的地址空间，操作系统需要将进程的逻辑地址转换为物理内存中的实际地址，这一过程可以由不同方法实现。 在早期的计算机中，同一时间在机器上运行的只有一个作业，因此这个进程的地址空间与实际物理内存是完全重合的，不需要进行地址的转换。在多道程序设计与操作系统逐渐形成后，操作系统必须将多个程序相互不覆盖地放入物理内存。为了达到这一目的，多种连续内存管理方法和非连续内存管理方法都逐渐被发明和采用。在介绍连连续内存管理和非连续内存管理的不同实现方法之前，我们必须先了解 “**碎片**”（fragmentation） 的概念和评价一个内存管理方法的标准，这样每学习一个新的实现方法后，我们都可以依照这个标准来评价其优缺点，对这个方法有更完全的认识。

碎片即在内存中无法有效利用的部分，分为**外部碎片**和**内部碎片**。外部碎片（external fragmentation） 指的是因为长度过短而无法被使用的 未分配内存；相对的，内部碎片（internal fragmentation） 指的是 已分配内存 中因为分配长度过长而没有被进程有效利用的内存。

在评价一个用来实现地址转换和内存分配的方法时，我们需要考虑到这个方法是否会造成大量碎片的出现，或者在实际实现的过程中过于复杂、占用过多内存。理想的内存分配和地址转换方法能够达到保护进程不被其它恶意进程读取其内容、保护进程不能修改自己的代码、方便进程在运行过程中获取更多内存或与其它进程共享一部分内存的目的，又不需要过多的内存空间存储地址转换需要的信息或长的时间实现地址转换或内存分配，同时又不产生内部碎片和外部碎片

### 连续内存管理

为了实现多道程序在系统中同时运行，我们必须设计一个内存管理方法使不同程序的数据可以同时存在于内存中而不相互干扰。早期计算机中为了达到这一目的使用的方法是**连续内存管理**。 顾名思义，连续内存管理会将同一个进程的地址空间映射到一段连续的物理内存上。早期被用来实现连续内存管理的方法是 **固定分区存储管理**（fixed partition），即将内存空间分为数目固定的分区，其中每个分区大小都与其它分区不同，一个分区只对应一个进程，处于不同分区中的进程将并发执行。显然，为了能够有效地将为新进入系统的作业选择分区，我们需要一种记录未被使用的分区的方法，这就是**内存分配表**。内存分配表中记录了内存中所有被划分的分区的大小及使用情况，可以帮助我们为新进入系统的进程选择分区。

我们不难看出，将内存划分为大小合理的分区对于提高固定分区存储管理的效率是非常重要的。这一工作往往由系统管理员和操作系统共同完成，但这仍然不能完全避免内部碎片的问题。更糟糕的是，如果一个进程所需的内存大小大于最大分区的大小，那么系统就必须合并多个分区，而这是需要很多工作来实现的。另一方面，如果系统管理员事先知道最大作业的大小而将一个分区设为该大小，那么该分区在运行其它进程时很可能产生很大的内部碎片。另外，如果一个进程在运行时发现需要更多空间，那么固定分区的存储方式很难给这个进程分配新的分区。最后，我们知道在现代系统中很多时候进程的数量是很少的，而少部分时候进程数量会很多，造成拥堵，固定分区的管理方法限制了分区的数量，因此不适于处理这种情况。

为了解决前面提到的内部碎片和无法容纳过大进程的问题，我们可以采取一种更具有变通性的方法实现连续内存管理；这种方法就是 **可变分区存储管理**（variable partition）。 

这种管理方式按照不同进程所需的内存大小划分分区，并将所有未分配分区存放在一个链表中。在一个进程结束、被系统撤销后，它所占的分区将被标记为可用，加入未分配分区的链表；如果其毗邻的分区也为未分配分区，那么它们就会被合为一个更大的未分配分区加入链表。在一个新的进程进入系统时，系统将沿链表寻找可以容纳该进程的未分配分区，将进程需要的大小分配给该进程，将该分区中剩余的内存作为一个新的未分配分区加入链表。

我们提到的 Base & Bound 这一地址转换的方法，实际上就是这一节里我们所提到的连续内存管理。每一个进程在获得一段连续的内存后将内存的 基地址（Base） 和 限长（Bound） 存入进程控制块中；每次进程需要读写内存时，系统利用进程控制块中存储的基地址和限长检查进程是否企图使用超出其分配范围外的内存，从而达到保护进程不受其它进程侵害的目的。

### 可变分区存储管理的实现

为了在可变分区存储管理中最有效地分配分区，使新进程在进入系统时即可以找到适合其大小的分区而不产生过多碎片，我们可以采取不同的方法排列未分配分区链表中的分区并选择相应的算法来分配分区。针对未分配分区的分配有五种不同的算法

- 最先适应
  - 顺序查找未分配分区的链表，选择第一个能满足长度要求的分区。采取这种算法时未分配区表中的空闲区往往**按照地址从低到高排列**，这样高地址部分的内存尽量不被分割，可以被留给内存需求大的进程。尽管这种算法使低地址空间的使用率远高于高地址空间并在低地址空间产生了许多小的未分配分区，在实际的系统中，这种算法由于其快速、便于实现的特点被广泛应用。 
- 下次适应（next fit）
  - 这种算法会保留一个搜索指针，每次总是**从上次未分配分区的扫描结束处开始扫描**，直到找到第一个能满足长度要求的空闲区。这种算法相比第一种对存储空间的利用率较为均衡，不会使碎片化的空闲区集中在低地址部分。
- 最优适应（best fit）
  - 这种算法在每一个新进程进入系统时都扫描整个未分配分区链表，寻找最小的可满足该进程内存需求的未分配分区。使用这种算法时往往把分区**按大小升序排列**，方便找到符合要求的最小分区。这种算法的问题是每次分配分区后，该分区中大于进程所需内存大小的部分可能很小，因此会在未分配分区链表中加入很多很小的分区，不能被任何进程使用，而导致外部碎片的产生。 
- 最坏适应（worst fit）
  - 与上一种相反，这种算法总是将最大的未分配分区分割给作业使用，这样分配的分区中剩下的分区总不会过小。使用这种算法时，我们总是将未分配分区**按大小降序排列**，使找到最长的分区非常快速。
- 快速适应（quick fit）
  - 这种算法给一些常用的分区长度设立了单独的链表（如：2KB，4KB 和 8KB 的分区可能分别对应一个单独的链表）。我们把大小接近这些分区的分区也放在这些分区的链表中（如：5KB 分区可以放在 4KB 的链表中）。这样，在一个新进程进入系统中时，我们可以将可以容纳该进程的最小长度的链表的第一个分区分给它。这种算法非常快速，但在归还分区和合并未分配分区时非常复杂。

### 内存不足的解决方法

连续内存的存储面临一个比较大的问题，即难以获得大小足够的连续内存用于分配给一个进程。这种情况又可以被细分为两种情况：

- 一种情况是，系统中未分配内存的总量大于进程需要的内存。我们可以通过合并分区解决内存不足的问题。移动技术
- 另一种情况是，系统中未分配内存的总量小于进程需要的内存。我们必须将一部分现在处于内存中的东西移到外存中。覆盖技术和对换技术

**移动技术**就是通过读出已分配内存中的全部数据并写回内存中的另一位置将进程的内存分区移动到一起，使未分配分区集中到一个位置合为一个大的未分配分区，分配给新进程。 

这种方法的问题是很明显的：如果一个进程正在读写它的分区，那么系统就不能移动这个分区；而移动过程中，进程也不能读写其内存，这将延长所有进程的响应时间。因此系统一般会尽量避免移动，只在必须通过移动分区来容纳新进程，或进程撤销后释放出的空闲分区与其它未分配分区不相邻时才移动分区来合并未分配分区。

当系统中的未分配内存总量已经小于进程所需的内存总量时，我们就必须将一部分数据移出内存。在这种情况下我们经常使用的技术是覆盖技术和对换技术，这里我们先来解释**覆盖技术**。

覆盖技术要求程序开发者将自己的程序分为几个“覆盖段”，每个覆盖段中含有多个相对独立的程序部分，称为“覆盖”。处于同一覆盖段中的覆盖相互没有依赖关系，所以不需要同时处于内存中。我们以每个覆盖段中最大的覆盖的大小来规定该覆盖段的大小；在每个覆盖段中，所有覆盖按一定的顺序进入内存，这样系统在给这个进程分配内存时，就只需要分配大小等于该进程所有覆盖段大小之和的内存，节省了很多空间。

 这个技术给程序开发者提高了程序设计的难度，因为他们必须能够将程序分为互相不依赖的模块，并设计不同模块进入内存的顺序，这是十分困难的。因此，这种技术只在早期的计算机中被使用，现在经常被使用的是我们下面要提到的这种技术——**对换技术**（swapping）。

对换技术的概念非常简单，即将内存中的一部分移出内存，然后将总量小于等于被移出部分的大小的数据从外存移到内存中，但是我们面临着一个很重要的问题，即哪一部分内存应该被移出呢？ 

在连续内存管理中，由于每个进程都只有一块连续的内存，我们只能将整个进程都移出内存，因此我们一般会选择处于等待态的进程移出内存。如果我们选择运行态或就绪态的进程移出内存，那么这个进程的响应时间就会被延长，影响系统效率。但是如果没有进程处于等待态，我们应该把哪一部分内存移出呢？参考上面的覆盖技术我们可以知道，一个进程并不是同时需要其地址空间的所有部分都处于内存中，**因此理想状态下，我们应该可以只把运行需要的部分留在内存中，而系统将自动把其它部分移出。这就是非连续存储管理的意义**。

### 分段内存管理

分段存储管理会将进程的逻辑地址分为两部分，**段号和段内位移**。每一个进入系统的进程都会拥有自己的**段表**，表中的每一行都对应着段号等于行号的段的段长和基址，以及一些用于限制这一段的操作权限的保护位（如是否可读、可写）。这样我们就可以通过段号获取逻辑地址所对应的段的基址，然后将段长与位移作比较，如果位移未超过段长则将位移与基址相加，得到实际的物理地址。由于系统对于段号和段内位移的尾数做出了限制，如果在 32 位系统中段号由 i 位组成，则用户进程在设计分段时不能设计超出 2^i 个段，每段长度不能超过 2^{32-i}字节。

每次进程在对内存进行操作时，都必须用段号作为行号进入该进程的段表，获取基址和段长；如果段号大于该进程的最大段号，或进程对这一地址的操作不被该段允许，或逻辑地址中的段内位移大于段长，则硬件会触发异常，这就是你在写 C 程序时可能会见到的**段错误**（Segmentation fault）。

![img](https://i.loli.net/2020/10/11/q59asZkmQAyo4OF.png)

分段存储的优点是，不同进程间可以共享一段逻辑上相对独立的内存，比如两个运行同一程序的进程可以共享代码分段，两个公用一个库的进程可以共享只包含这个库的段。但分段存储也有一个明显的缺点——与可变分区存储管理相似，它的每一个段大小不固定，因此可能面临内存中存在很多外部碎片，需要移动已有进程才能运行新进程的局面。为了解决这一问题，我们可能希望每一个段都有相同的大小，或可以被分为大小相同的更小单位来存储，这就是我们即将介绍的 **分页存储管理**（Paging）。

### 分页存储管理

页与段类似，都是进程地址空间中的一部分，但不同于段的是，一个系统中所有页面的大小都是固定、相等的。页面的一般大小都是 2 的整数次幂字节，因此如果一个页面的大小是 2^j字节，那么在 32 位系统中，我们就可以用地址最右侧的 j 位表示页内位移，左侧的 32-j位表示页号。为了区分进程地址空间和物理内存，我们将物理内存中同样大小的内存单位称为页框.

为了将地址空间中的页与物理内存里的页框相对应，每一个进程有自己的页表，长度由进程所需的页面数决定，我们可以在第 b 行查看页面号（逻辑地址）等于 b 的页面在物理内存中对应的实际页框号。第 b 行中同时也包含一些其他的信息，如读写权限位（read bit and write bit）、表示页面是否实际存在于内存中的有效位（valid bit）、表示页面是否被修改过的 页面重写标志位（dirty bit） 等等，我们会在讲到请求分页虚拟存储管理时更具体地讲到这些内容。 

从页表中获得页框号后，我们可以将页框号与位移合成该逻辑地址对应的物理地址。为了分配页面给不同的进程，系统将需要一个内存物理块表，用来记录页框状态，即哪些页框还未被分配，已分配的页框属于哪些进程等等；在新进程进入系统后，我们将在内存物理块表中寻找未被分配的页框给这个进程使用。

![img](https://i.loli.net/2020/10/11/R7wpIH93F4ThtOf.png)

分页存储的优点是，由于内存大小是页面大小的整数倍，内存中永远不会像分段处理那样出现外部碎片。不仅如此，由于每个进程无法不通过页表获得物理地址，用户进程自然不能接触其它进程未与之共享的物理地址；而共享本身也变得简单了许多，只需要将不同进程中的两个页面指向同一个页框。当然，它也面临着很严重的问题——页表本身需要很大的空间储存，可能占去很多内存空间。为了解决这个问题，我们将在后几节中介绍多级页表、反置页表和分段与分页结合的存储管理。

### 分页和分段的对比和结合

分段与分页都会将一个进程的地址空间分为几个小段，将这些小段分别存储在连续的一段内存中，但同一进程的不同段可能存储在不连续的内存中；它们的不同点在于，分页完全根据一个固定的大小将内存分为大小相等的段，与内存中所存储的内容无关，而分段存储管理是根据内存的逻辑结构将内存分为几个部分。一种常见的分段方法是将进程内存分为代码、数据、栈和堆四部分，然后将这几个部分分别存放在几段可能相互不连续的内存中；而在分页的存储模式中，栈可能会分布在几个在物理内存中不连续的页面中。另一点不同是，在分页存储管理中，页的划分是用户进程不可见的；而在分段存储管理中，段的划分是用户进程可见的，可以根据自己的需求和逻辑地址结构的限制来自行划分段。

分段和分页也可以被结合起来使用：我们可以将每个段对应一个页表，这样每次需要将内存中的一些部分与外存中的部分对换时，我们可以只对换某一段中的一页，而不是将整个段移出内存，这就解决了分段内存中由段落大小不同造成的外部碎片问题。

### 虚拟存储，多级页表，反置页表

32 位的系统中使用 4KB 的页面会导致每个进程的页表可以消耗 2MB 的内存。这对于 32 位系统 2^{32}字节，也就是 4GB 的内存来讲已经很大了。在现代的计算机系统的发展中，人们意识到一个进程可能并不随时需要其全部的程序和数据来运行，因此可以进一步扩大进程的地址空间，将地址空间的一部分储存到磁盘上，只将运行用到的部分放在物理内存中。这种想法允许一个进程拥有与物理内存大小相同甚至大于物理内存大小的地址空间；因此**虚拟存储器**诞生了。在将虚拟存储中的逻辑地址转换为物理内存的实际地址时，我们需要的页表的大小是与虚拟存储中的总页面数量成正比的；由于虚拟存储很可能大于物理内存，一个页表消耗的内存可能远高于 2MB。为了解决这种过度的内存消耗，我们接下来将介绍两种能够更节约空间地将页面号转换为页框号的方法。

**多级页表**的想法很简单，即将原来的页号分为两部分，用第一部分将原来的大页表分为几个小页表，称为页表页，将每个页表页分别存在内存的一个位置，然后将这些位置与我们用来区分页表页的页面号的第一部分一一对应，形成一个页目录表。我们在转换地址时先通过页号的第一部分页表目录找到一个页表页，然后再用页号的第二部分在该页表页中找到页框号；因此我们将页号的第一部分称为页目录位移，页号的第二部分称为页表页位移。 我们还剩下一个问题，我们该如何决定页目录位移包含多少位呢？假设在一个 32 位系统中，每个页面为 2^{i} KB，页表中每行为 2^j B，那么内存中总共有 2^{22-i}个页面，每个页表页可以装下 2^{10+i-j}个页表项。因此我们需要 2^{22-i-10-i+j} = 2^{12-2i+j}个页表页来包含所有页面。因此，我们需要 12-2i+j 位来表示页目录位移，10+i-j 位来表示页表页位移，10+i 位来表示页位移。我们可以验证一下我们的计算： 12-2i+j+10+i-j+10+i = 32。

多级页表相对于单级页表的优势是，我们不需要将所有页表页留在内存中——我们只需要那些近期使用过或正在使用的页表留在内存中，而这可以帮我们节约大量内存。但多级页表也面临着一个问题——即使一个页面和它对应的页表页都存在于内存中，我们也需要三次访问内存，才能获得我们需要的数据——第一次访问内存我们从页目录表中获取了该页表页的起始地址，第二次访问内存时我们从页表页获得了页框号，第三次访问内存时我们才获得了我们需要的实际数据。这本身就需要很多时间；如果在这个过程中，我们发现其中一个页面不在内存中，那么我们还要花更多的时间将页面从磁盘中复制到内存中，多级页表的缺陷就体现出来了。

![img](https://i.loli.net/2020/10/11/PFgubcjBAMzsm1q.png)

与多级页表并列的另一种方法是 **反置页表**（Inverted Page Table），它的特点是所有进程都被包含在 一张表中。这种方法将逻辑地址中的页号与该进程的进程标识符结合起来作为哈希函数的输入，被哈希函数映射到一个反置页表项上。一个反置页表项包括进程标识符、页号和哈希链指针；哈希指针是一个指向反置页表中的其它项的指针，它被用来解决哈希函数中不同进程的不同逻辑页面指向同一个反置页表项的问题。如果反置页表项中的进程标识符合页号与逻辑地址中的进程标识符和页号相同，这说明物理内存中的这一页框确实对应着逻辑地址空间中的这一页面，我们可以直接将页框号与页内位移组合在一起，获得物理地址。反之，我们就必须沿哈希指针寻找符合该逻辑地址的进程标识符和页号的项，如果我们找不到这样一个项，那就说明该页面不在物理内存中，此时系统就会触发缺页异常，将页面从磁盘中复制到内存中。

反置页表相对于多级页表的优势是很明显的——对于在物理内存中的页面，我们可能只需要访问一次内存；相对于普通页表，它的大小是与物理内存中的页面数量成正比的，因此所占的内存远小于普通页表。但它的问题也非常明显——表中包含的只有在物理内存中的页面，对于不在物理内存中的页面，进程仍需建立普通页表存储，而且反置页表相对其它方式需要更复杂的硬件结构来实现。

![img](https://i.loli.net/2020/10/11/peIm1o6Dyshwgk5.png)

### 应用可变分区存储管理实现malloc

malloc()用于动态分配一定大小的内存的功能，但这是如何被系统实现的呢？ 

为了实现malloc()的功能，我们需要有办法从堆内存的起始部分开始寻找空闲的区域，并知道堆内存的上限；为了能够用free()将已分配的内存回收，或用realloc()调整已分配的内存大小，我们需要一种方式，通过malloc()返回的指针获取分配内存的大小。为了获得堆内存的上限，我们可以使用sbrk()系统调用；为了包含其它两种信息，我们需要一个数据结构和对应的算法来保存和使用这些信息。在这一节中，我们将先介绍sbrk()的用法，然后介绍三种用来保存已分配内存的大小和位置的数据结构和算法。

```cpp
void *sbrk(intptr_t increment);
```

sbrk()可以被用来调整一个程序的数据段的终止地址，即 program break。它在现有的基础上将 program break 提高increment字节。sbrk()在成功时返回调整前的 program break 位置，否则返回 (void*) -1。 在实现malloc()时，我们之所以需要这个函数是因为堆内存在程序初始时大小为 0，其大小是随着进程请求堆内存分配后才逐渐变大的。在我们寻找一个空闲分区分配给进程时，我们如果从堆的起始地址开始搜索直到触及 program break 都无法找到合适大小的分区，那我们就需要用sbrk()提升堆内存的上限。

从上面的介绍中，我们可以想象的第一种直接的实现方法就是在堆内存的开头存放一个字典，将每块分配的内存的信息都作为一个数据项存放在字典中。为了能够实现malloc()、realloc()和free()的功能，我们需要在一个数据项中记录分配内存的位置和大小。因此我们的字典和数据项可能是这样的：

```cpp
struct dictionary_entry{
    void *address;
    size_t size;
    int is_free;
};
struct dictionary_entry dictionary[NUM_OF_ENTRIES];
```

但这样我们就遇上了一个问题——我们如何知道应该在字典中存放多少个数据项？假如说我们在字典里存放了+nn+个数据项，然后从字典之后的内存开始分配给进程，那在我们需要更多数据项时，我们是否需要将所有已分配的内存向后移动？这自然而然地将我们引向了第二种结构，即将每段包含了信息的数据结构存放在其对应的被分配内存的前面。)

![image-20201011100744238](https://i.loli.net/2020/10/11/Q4Tk2iulMvqW9w8.png)

我们将这种存放方法称为 metadata。在每次给用户进程分配新的堆内存时，我们都在分配的区域前存放一段大小固定的信息。这段信息必须包含我们上面提到的这段分配内存的大小，但它也需要一些别的信息，因为现在一段被分配内存无法直接获得下一段被分配内存开始的区域。我们所需要的数据结构可能是这样的：

```cpp
struct metadat {
    size_t size;
    void *next_block;
    void *prev_block;
    int is_free;
}
```

这样我们在寻找一个空闲的数据块来分配给进程时，就可以从堆内存的起始地址开始，跟随着 metadata 中包含的前往下一个数据块的指针，找到最合适的空闲数据块。

metadata 的方法成功地解决了字典方法所面临的数据项数量未知的问题，但它也有它自己的问题——它和我们前面提到的可变分区存储管理在本质上是一样的，都面临着外部碎片的问题。在进程释放了堆内存之后，堆内存中将会存在很多大小不等，穿插在已分配内存中的空闲数据块；一段时间后，我们可能遭遇堆内存已无法继续得到新的内存分配、堆内存中空闲数据块的总量大于进程需要的内存、但没有合适大小的空闲数据块的局面。我们想要一个能帮我们解决这一问题的分配方法，这就是 **伙伴系统**（buddy system）。

 伙伴系统的基本思想是，将进程请求的堆内存大小变为大于等于请求数据块的最小的 22 的整数次幂（如：如果用户请求 77 字节的堆内存，则将 77 约为 2^32 3 =8 字节），然后在堆内存中寻找该大小的数据块，如果没有该大小的内存，则将一个大小为该数据块的二倍的数据块分为两半，互为对方的“伙伴”，其中一半用来返回给用户。为了记录每个数据块是否空闲，我们给每一个大小等级的数据块都建立一个 **位映像**（bitmap），用来表示每块数据是否已经被应用；每次分配新数据块时，我们在对应的数组中寻找空闲的数据块。

![img](https://i.loli.net/2020/10/11/s6kDLMjxfGUQ1FR.png)

伙伴系统相对于其它两种方法的一大优势是效率较高，因为按照这种分配方法，一对大小都为 2^i 字节的伙伴的地址只在第 i 位不同，一个为 0，另一个为 1。因此我们在寻找空闲的数据块时只需要使用位运算，节省了很多时间。伙伴系统的缺陷在于用户进程请求的内存越大，其产生大的内部碎片的可能性也就越高；如果一个用户请求 140 字节的堆内存，那么系统将会把一个 256 字节的数据块分配给这个用户，数据块中将近一半的内存都成为了内部碎片